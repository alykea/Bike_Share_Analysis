---
title: "Bike Share Analysis"
author: "Aly"
date: "2023-05-17"
output: 
  html_document:
    toc: true
    number_sections: true
    keep_md: true
---


### **Introduction**  
  
**Case - How to optimize the amount of annual memberships?**

I used historical data from a bike-share company located in Chicago, IL, USA to *analyze how casual riders and annual members use bikes differently*. Annual members are more profitable than casual riders, so the goal is to maximize the number of annual members for future company growth.  

  
  
### **ASK**  
  
**Key Task:**  

1. Business task: **analyze the different ways riders use the bike-share service to identify historical trends and convert casual riders into annual members in order to grow the company.**  
  
  
### **PREPARE**  
  
**Key Tasks:**  

1. Download data and store it appropriately.  
2. Identify organization of the data.  
3. Determine credibility of the data.  
4. Sort and filter data.  
  
12 months worth of data was downloaded from [divvy](https://divvy-tripdata.s3.amazonaws.com/index.html) and stored on a password protected hard drive. The data is organized into monthly CSV files. The data has been made publicly available by Motivate International Inc. under this [license](https://ride.divvybikes.com/data-license-agreement). The data contains no personal identifiable information and was collected from **May 1, 2022 to April 30, 2023**.  
  
**The data is:**  

* **RELIABLE** - Yes, the data sample is representative of the population of Cyclistic riders because it includes 12 months worth of data.  
* **ORIGINAL** - Yes, the data set is from the original source.  
* **COMPREHENSIVE** - Yes, the data set contains comprehensive information such as the different types of bikes, the time when the trip begins and ends, the location of where the trip begins and ends, and what types of customers they are. It does not contain any personal identifiable information.  
* **CURRENT** - Yes, the data set is updated on a monthly basis.  
* **CITED** - Yes, the data is being collected by the company themselves.  
  

**Potential pattern differences include:**  

* Duration of ride lengths 
* Usage by day of week, month of the year, and hour of the day  
* Popularity of the three types of bikes  
* Popularity of different start and end stations  

**Potential problems include:**  

* Duplicate ride_ids could indicate duplicate data  
* Rides that are negative duration or less than 0s  
* Rides lasting 0 to 60s  
* Rides lasting more than 24h  
* Rides to or from TEST or NULL stations  
* Data can only be aggregated at the ride-level  

**Solutions include:**  

* Check for uniqueness of ride_ids.  
* Filter out negative duration rides.  
* Filter out rides outside of 60s-24h.  
* Filter out rides to or from TEST or NULL stations.  
* Add additional columns to provide more opportunities to aggregate data.  

**Results include:**

* Before cleaning: **5.9 million rows**  
* Eliminated ~1.5 million rows of bad data (approximately 26% of the raw data set).  
* Ensured approximately the same ratio of member to casual rides in the clean data set as the raw data set (approximately 67.4% in raw data and 65.4% in clean data for casual to member ratio) to minimize bias.  
* After cleaning: **4.4 million rows**

**Load the following packages:**
```{r}
# help analyze and wrangle data
library(tidyverse)
# skim data quickly
library(skimr)
# examine and clean data
library(janitor)
# make interactive maps
library(mapview)
```

**Load the data:**
```{r}
c202205 <- read_csv("202205-divvy-tripdata.csv")
c202206 <- read_csv("202206-divvy-tripdata.csv")
c202207 <- read_csv("202207-divvy-tripdata.csv")
c202208 <- read_csv("202208-divvy-tripdata.csv")
c202209 <- read_csv("202209-divvy-tripdata.csv")
c202210 <- read_csv("202210-divvy-tripdata.csv")
c202211 <- read_csv("202211-divvy-tripdata.csv")
c202212 <- read_csv("202212-divvy-tripdata.csv")
c202301 <- read_csv("202301-divvy-tripdata.csv")
c202302 <- read_csv("202302-divvy-tripdata.csv")
c202303 <- read_csv("202303-divvy-tripdata.csv")
c202304 <- read_csv("202304-divvy-tripdata.csv")
```

### **PROCESS**  
  
**Key Tasks:**  

1. Choose your tools.  
2. Check the data for errors.  
3. Transform the data so you can work with it effectively.  
4. Document the cleaning process with a changelog.  
  
**Tools:** RStudio was used for data preparation and analysis due to the large amount of data. RMarkdown was used to generate a high quality report.  

**Data Errors:** To ensure data integrity, I used a changelog to document the cleaning process to eliminate human errors including filtering out negative, too short, or too long ride durations, checking for inconsistencies across all formats so that all data gets aggregated appropriately, and using 12 months worth of data to ensure the data collected is not lacking information and to prevent bias.  

**Merge the data:**  
```{r}
# merging all data sets into one
Annual_bike_sales <- bind_rows(c202205,c202206,c202207,c202208,c202209,c202210,c202211,c202212,c202301,c202302,c202303,c202304)
```

**Check if column names are consistent:**
```{r}
# ensure consistent column names
colnames(Annual_bike_sales)
```


**Inspect merged table:**
```{r}
# broad overview of the data frame
skim_without_charts(Annual_bike_sales)

# see FIRST 6 rows
head(Annual_bike_sales)

# see LAST 6 rows
tail(Annual_bike_sales)

# view the statistical summary of the data
summary(Annual_bike_sales)
```

**Check for uniqueness of ride_ids:**
```{r}
# find number of duplicate ride_ids
sum(duplicated(Annual_bike_sales$ride_id))
```

**Filter out NULL values:**
```{r}
# sum of NULL values by column
sapply(Annual_bike_sales, function(x) sum(is.na(x)))

# filter out NULL values across all columns
Annual_bike_sales_clean <- na.omit(Annual_bike_sales)

# confirm NULL values have been removed
sapply(Annual_bike_sales_clean, function(x) sum(is.na(x)))
```

**Filter out TEST rides:**
```{r}
# check for test rides in start station names
sum(str_detect(Annual_bike_sales_clean$start_station_name, 'Base'))

# filter out test rides in start station names
Annual_bike_sales_clean <- Annual_bike_sales_clean %>% 
  filter(!grepl('Base', start_station_name))

# confirm test rides removed in start station names
sum(str_detect(Annual_bike_sales_clean$start_station_name, 'Base'))

# check for test rides in end station names
sum(str_detect(Annual_bike_sales_clean$end_station_name, 'Base'))

# filter out test rides in end station names
Annual_bike_sales_clean <- Annual_bike_sales_clean %>% 
  filter(!grepl('Base', end_station_name))

# confirm test rides removed in end station names
sum(str_detect(Annual_bike_sales_clean$end_station_name, 'Base'))
```

**Add additional columns to find usage differences:**
```{r}
# adding ride length column
Annual_bike_sales_clean <- Annual_bike_sales_clean %>%
  mutate(ride_length = difftime(ended_at, started_at,units = "mins"))

# adding date column
Annual_bike_sales_clean$date <- as.Date(Annual_bike_sales_clean$started_at)

# adding month column
Annual_bike_sales_clean$month <- format(as.Date(Annual_bike_sales_clean$date), "%m")

# adding day column
Annual_bike_sales_clean$day <- format(as.Date(Annual_bike_sales_clean$date), "%d")

# adding year column
Annual_bike_sales_clean$year <- format(as.Date(Annual_bike_sales_clean$date), "%Y")

# adding day of week column
Annual_bike_sales_clean$day_of_week <- format(as.Date(Annual_bike_sales_clean$date), "%A")

# adding hour column
Annual_bike_sales_clean$hour <- format(as.POSIXct(Annual_bike_sales_clean$started_at), "%H")
```

**Inspect new data set:**
```{r}
# check new columns were formatted correctly
skim_without_charts(Annual_bike_sales_clean)
```

**Filter out negative, <1min, and >24hr rides:**
```{r}
# see how many ride lengths are outliers
length(which(Annual_bike_sales_clean$ride_length > 1440 | Annual_bike_sales_clean$ride_length<1))

# filter out negative, <1min, and >24hr rides
Annual_bike_sales_clean <- Annual_bike_sales_clean %>% filter(ride_length < 1440, ride_length > 1)

# confirm ride duration deletions
length(which(Annual_bike_sales_clean$ride_length>1440 | Annual_bike_sales_clean$ride_length<1))
```

**Remove <2min rides with same start and end station:**
```{r}
# create new df with same start and end stations and rides are less than 2mins
same_start_and_end <- Annual_bike_sales_clean %>%
  filter(start_station_name==end_station_name, ride_length < 2) %>%
  arrange(desc(ride_length))

# show tibble of new df to be removed
print(same_start_and_end)

# remove new df from clean data set (new df not meaningful)
Annual_bike_sales_clean <- Annual_bike_sales_clean %>%
  anti_join(same_start_and_end)
```

**Compare the ratio of annual members to casual riders for RAW and CLEAN data to ensure unbiased data sample:**  
```{r}
# count number of annual members and casual riders in the raw data
praw <- Annual_bike_sales %>%
  count(member_casual) %>%
  select(member_casual, n)

# show raw df numbers
print(praw)

# calculate member to casual ratio for raw data
praw[1,2]/praw[2,2] * 100

# count number of annual members and casual riders in the clean data
pclean <- Annual_bike_sales_clean %>%
  count(member_casual) %>%
  select(member_casual, n)

#show clean df numbers
print(pclean)

# calculate member to casual ratio for clean data
pclean[1,2]/pclean[2,2] * 100
```

**Inspect overview of the cleaned data set:**
```{r}
# broad overview of cleaned data set
skim_without_charts(Annual_bike_sales_clean)
```

### **ANALYZE**  
  
**Key Tasks:**  

1. Organize and format data.  
2. Perform calculations.  
3. Identify trends and relationships.  
  
Each row is associated to an annual member or casual rider and is a collection of rides organized by location, date, duration, and type of bike.

**Structure of the data:**  

* **Ride ID** - ID associated with different users  
* **Rideable Type** - type of bike used  
* **Started At** - date and time (YYYY-MM-DD HH:MM:SS) of when the ride starts   
* **Ended At** - date and time (YYYY-MM-DD HH:MM:SS) of when the ride ends  
* **Start Station Name** - name of starting station  
* **Start Station ID** - ID of starting station  
* **End Station Name** - name of ending station  
* **End Station ID** - ID of ending station  
* **Start Lat** - starting latitude  
* **Start Lng** - starting longitude  
* **End Lat** - ending latitude  
* **End Lng** - ending longitude  
* **Member / Casual** - type of rider  
* **Ride Length** - duration of the ride  
* **Date** - date of the ride (YYYY-MM-DD)  
* **Month** - month of the ride  
* **Day** - numerical day of the month of the ride  
* **Year** - year of the ride  
* **Day of Week** - day of the week of the ride  
* **Hour** - hour of the day of the ride  


**Sum by rider type:**
```{r}
# find the annual sum by type of rider
nrow(Annual_bike_sales_clean[Annual_bike_sales_clean$member_casual=='member',])
nrow(Annual_bike_sales_clean[Annual_bike_sales_clean$member_casual=='casual',])
```

**Descriptive analysis and correctness check on ride_length:**
```{r}
# find the mean
mean(Annual_bike_sales_clean$ride_length)

# find the median
median(Annual_bike_sales_clean$ride_length)

# find the max
max(Annual_bike_sales_clean$ride_length)

# find the min
min(Annual_bike_sales_clean$ride_length)
```

**View summary of length of ride:**
```{r}
# summary of ride_length
skim_without_charts(Annual_bike_sales_clean$ride_length)
```

**Compare length of rides between rider types:**
```{r}
# compare the mean
aggregate(Annual_bike_sales_clean$ride_length ~ Annual_bike_sales_clean$member_casual, FUN = mean)

# compare the median
aggregate(Annual_bike_sales_clean$ride_length ~ Annual_bike_sales_clean$member_casual, FUN = median)

# compare the max
aggregate(Annual_bike_sales_clean$ride_length ~ Annual_bike_sales_clean$member_casual, FUN = max)

# compare the min
aggregate(Annual_bike_sales_clean$ride_length ~ Annual_bike_sales_clean$member_casual, FUN = min)
```

**View average ride time by each day and rider type:**
```{r}
# set order of the days of the week
Annual_bike_sales_clean$day_of_week <- ordered(Annual_bike_sales_clean$day_of_week, levels=c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))

# average ride_length by each day by type of user
aggregate(Annual_bike_sales_clean$ride_length ~ Annual_bike_sales_clean$member_casual + Annual_bike_sales_clean$day_of_week, FUN = mean)
```

**Analyze by rider type and weekday:**
```{r}
# view tibble of rider type, day of week, number of rides, and average duration
Annual_bike_sales_clean %>%
  mutate(weekday = wday(started_at, label=TRUE)) %>%
  group_by(member_casual, weekday) %>%
  summarise(number_of_rides = n(), average_duration = mean(ride_length)) %>%
  arrange(member_casual, weekday)
```

**Visualize average duration by rider type:**
```{r}
# set min date
mindate <- min(Annual_bike_sales_clean$date)
# set max date
maxdate <- max(Annual_bike_sales_clean$date)

# bar graph of average duration by weekday and rider type
Annual_bike_sales_clean %>%
  mutate(weekday = wday(started_at, label = TRUE)) %>%
  group_by(member_casual, weekday) %>%
  summarise(number_of_rides = n(), average_duration = mean(ride_length)) %>%
  arrange(member_casual, weekday) %>%
  ggplot(aes(x = weekday, y = average_duration, fill = member_casual)) +
  geom_col(position = "dodge") +
  labs(title="Average Duration: Casuals VS Members", caption=paste0("Data from ",mindate," to ",maxdate), x="Weekday",y="Average Duration")
```

**Visualize the average of daily rides by rider type:**
```{r}
# bar graph of number of rides by weekday and rider type
Annual_bike_sales_clean %>%
  mutate(weekday = wday(started_at, label=TRUE)) %>%
  group_by(member_casual, weekday) %>%
  summarise(number_of_rides = n(), average_duration = mean(ride_length)) %>%
  arrange(member_casual, weekday) %>%
  ggplot(aes(x = weekday, y = number_of_rides, fill = member_casual)) +
  geom_col(position = "dodge") +
  labs(title="Average Daily Rides: Casuals VS Members", caption=paste0("Data from ",mindate," to ",maxdate), x="Weekday",y="Number of Rides")
```

**Visualize the number of rides monthly by rider type:**
```{r}
# tibble of monthly data
Annual_bike_sales_clean %>%
  select(month, member_casual) %>%
  add_count(month, member_casual) %>%
  distinct(month, n, .keep_all = TRUE) %>% # choose specific columns you want to perform distinct on
  arrange(desc(n)) %>%
  print(n=24)

# bar graph for yearly data by rider type
ggplot(data=Annual_bike_sales_clean)+
  geom_bar(mapping=aes(x=month,fill=member_casual))+
  theme(axis.text.x = element_text(angle=45))+
  labs(title="Monthly Rides: Casuals VS Members", caption=paste0("Data from: ", mindate, " to ", maxdate), x="Month", y="Number of Rides")
```

**Visualize the number of rides hourly by rider type:**
```{r}
# tibble of hourly data
Annual_bike_sales_clean %>%
  select(hour, member_casual) %>%
  add_count(hour, member_casual) %>%
  distinct(hour, n, .keep_all = TRUE) %>% # choose specific columns you want to perform distinct on
  arrange(desc(n)) %>%
  print(n=48)

# bar graph for hourly comparison by rider type
ggplot(data=Annual_bike_sales_clean)+
  geom_bar(mapping=aes(x=hour,fill=member_casual))+
  theme(axis.text.x = element_text(angle=45))+
  labs(title="Hourly Rides: Casuals VS Members", caption=paste0("Data from: ", mindate, " to ", maxdate), x="Hour", y="Number of Rides")
```

**Visualize the number of rides by type of bike:**
```{r}
# tibble of rideable_type data
Annual_bike_sales_clean %>%
  select(rideable_type, member_casual) %>%
  add_count(rideable_type, member_casual) %>%
  distinct(rideable_type, n, .keep_all = TRUE) %>% # choose specific columns you want to perform distinct on
  arrange(desc(n))

# bar graph for comparison of rideable types
ggplot(data=Annual_bike_sales_clean)+
  geom_bar(mapping=aes(x=rideable_type,fill=member_casual))+
  theme(axis.text.x = element_text(angle=45))+
  labs(title="Rides by Bike Type: Casuals VS Members", caption=paste0("Data from: ", mindate, " to ", maxdate), x="Type of Bike", y="Number of Rides")
```



**Visualize top 5 START stations by rider type:**
```{r}
# top 5 member start stations
top_start_member <- Annual_bike_sales_clean %>%
  select(start_station_name, start_lat, start_lng, member_casual) %>%
  add_count(start_station_name, member_casual) %>%
  filter(n>10000, member_casual=="member") %>%
  distinct(start_station_name, n, .keep_all = TRUE) %>% # choose specific columns you want to perform distinct on
  arrange(desc(n)) %>%
  slice(1:5)

# top 5 casual start stations
top_start_casual <- Annual_bike_sales_clean %>%
  select(start_station_name, start_lat, start_lng, member_casual) %>%
  add_count(start_station_name, member_casual) %>%
  filter(n>10000, member_casual=="casual") %>%
  distinct(start_station_name, n, .keep_all = TRUE) %>% # choose specific columns you want to perform distinct on
  arrange(desc(n)) %>%
  slice(1:5)

# combining top start stations member and casual data sets
top_start <- bind_rows(top_start_member, top_start_casual) %>%
  arrange(desc(n))
  
# view top start data set
print(top_start)

# visualizing top starting stations for members and casual riders
top_start %>%
  ggplot(aes(x = start_station_name, y=n, fill = member_casual)) +
  geom_col(position="dodge") +
  theme(axis.text.x = element_text(colour = "darkgray",size = 8, angle = 45)) +
  labs(title="Top Start Stations: Casuals VS Members", caption=paste0("Data from: ", mindate, " to ", maxdate), x="Start Station Name", y="Number of Rides")+
  scale_fill_manual(values=c("purple","blue"))
```

**Visualize the top 5 END stations by rider type:**
```{r}
# top 5 member end stations
top_end_member <- Annual_bike_sales_clean %>%
  select(end_station_name, end_lat, end_lng, member_casual) %>%
  add_count(end_station_name, member_casual) %>%
  filter(n>10000, member_casual=="member") %>%
  distinct(end_station_name, n, .keep_all = TRUE) %>% # choose specific columns you want to perform distinct on
  arrange(desc(n)) %>%
  slice(1:5)

# top 5 casual end stations
top_end_casual <- Annual_bike_sales_clean %>%
  select(end_station_name, end_lat, end_lng, member_casual) %>%
  add_count(end_station_name, member_casual) %>%
  filter(n>10000, member_casual=="casual") %>%
  distinct(end_station_name, n, .keep_all = TRUE) %>% # choose specific columns you want to perform distinct on
  arrange(desc(n)) %>%
  slice(1:5)

# combining top end stations member and casual data sets
top_end <- bind_rows(top_end_member, top_end_casual) %>%
  arrange(desc(n))

# view top end data set
print(top_end)

# visualizing top ending stations for members and casual riders
top_end %>%
  ggplot(aes(x = end_station_name, y=n, fill = member_casual)) +
  geom_col(position="dodge")+
  theme(axis.text.x = element_text(size = 8, angle = 45)) +
  labs(title="Top End Stations: Casuals VS Members", caption=paste0("Data from: ", mindate, " to ", maxdate), x="End Station Name", y="Number of Rides")+
  scale_fill_manual(values=c("lavender","lightblue"))
```

**Mapping top start and end stations:**
```{r}
# rename columns
top_start <- rename(top_start, member_casual_start = member_casual)
top_end <- rename(top_end, member_casual_end = member_casual)

# map top start and end stations
mapview(top_start, map.types = c("OpenStreetMap.DE"), xcol = "start_lng",
        ycol = "start_lat", zcol = "member_casual_start",  col.regions=c('purple','blue'),crs = 4269, grid = FALSE) + 
  mapview(top_end, map.types = c("OpenStreetMap.DE"), xcol = "end_lng",
        ycol = "end_lat", zcol = "member_casual_end", col.regions=c('lavender','lightblue'), crs = 4269, grid = FALSE)
```

**Visualize the top round trip stations by rider type:**
```{r}
# top 5 member round trip stations
top_round_member <- Annual_bike_sales_clean %>%
  filter(start_station_name==end_station_name) %>%
  select(start_station_name, end_station_name, start_lat, start_lng, member_casual) %>%
  add_count(start_station_name, end_station_name, member_casual) %>%
  filter(member_casual=="member") %>%
  distinct(start_station_name, n, .keep_all = TRUE) %>% # choose specific columns you want to perform distinct on
  arrange(desc(n)) %>%
  slice(1:5)

# top 5 casual round trip stations
top_round_casual <- Annual_bike_sales_clean %>%
  filter(start_station_name==end_station_name) %>%
  select(start_station_name, end_station_name, start_lat, start_lng, member_casual) %>%
  add_count(start_station_name, end_station_name, member_casual) %>%
  filter(member_casual=="casual") %>%
  distinct(start_station_name, n, .keep_all = TRUE) %>% # choose specific columns you want to perform distinct on
  arrange(desc(n)) %>%
  slice(1:5)

# combining round trip member and casual data sets
top_round <- bind_rows(top_round_member, top_round_casual) %>%
  arrange(desc(n))

# view new data set
print(top_round)

# visualizing top round trip stations for members and casual riders
top_round %>%
  ggplot(aes(x = start_station_name, y=n, fill = member_casual)) +
  geom_col(position="dodge") +
  theme(axis.text.x = element_text(colour = "darkgrey", size = 8, angle = 45))+
  labs(title="Top Round Trip Stations: Casuals VS Members", caption=paste0("Data from: ", mindate, " to ", maxdate), x="Station Name", y="Number of Rides")+
  scale_fill_manual(values=c("purple","yellow"))
```

**Mapping Top Round Trip Stations:**
```{r}
# Map top round trip stations
mapview(top_round, map.types = c("OpenStreetMap.DE"), xcol = "start_lng",
        ycol = "start_lat", zcol = "member_casual",  col.regions=c('purple','yellow'),crs = 4269, grid = FALSE)
```


### **SHARE**  
  
**Key Tasks:**  

1. Share findings and data visualizations.  
  
You may find my [pdf presentation](https://github.com/alykea/Bike_Share_Analysis/blob/main/bike_share_analysis_files/Bike_Share_Analysis.pdf). Or you can click on the file "bike_share_analysis_files" in my repo on GitHub.
